{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Data Load"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["True\n","pytorch version :  1.9.1\n","학습을 진행하는 기기: cuda:0\n","gpu 개수: 1\n","graphic name: NVIDIA GeForce RTX 3080 Ti\n"]}],"source":["import os\n","import sys\n","from glob import glob\n","import gc\n","import yaml\n","from pathlib import Path\n","import matplotlib \n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import torch \n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch.utils.data import RandomSampler\n","from torch.utils.data.dataset import random_split\n","from PIL import Image\n","import PIL\n","from tqdm import tqdm\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import transforms as T\n","\n","USE_CUDA = torch.cuda.is_available()\n","print(USE_CUDA)\n","device = torch.device('cuda:0' if USE_CUDA else 'cpu')\n","print('pytorch version : ',torch.__version__)\n","print('학습을 진행하는 기기:',device)\n","print('gpu 개수:', torch.cuda.device_count())\n","print('graphic name:', torch.cuda.get_device_name())"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["C:\\Users\\user\\Drive\\s-hero\\code\\yolov5\n"]}],"source":["# Yolov5 Extract\n","%cd C:\\Users\\user\\Drive\\s-hero\\code\\yolov5\n","!pip install -qr requirements.txt "]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2400,"status":"ok","timestamp":1629286899487,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"o08SouE0C2XF","outputId":"95eb7839-4b56-4a66-8490-612f8861b573"},"outputs":[{"name":"stdout","output_type":"stream","text":["575 192\n"]}],"source":["#이거\n","train_image_list = sorted(glob('C:/Users/user/Drive/s-hero/Code/Data/train/images/*.jpg'))\n","valid_image_list = sorted(glob('C:/Users/user/Drive/s-hero/Code/Data/valid/images/*.jpg'))\n","train_annotations_list = sorted(glob('C:/Users/user/Drive/s-hero/Code/Data/train/labels/*.txt'))\n","valid_annotations_list = sorted(glob('C:/Users/user/Drive/s-hero/Code/Data/valid/labels/*.txt'))\n","\n","assert len(train_image_list) == len(train_annotations_list), \"train 이미지 파일의 수와 annotation 파일의 수가 맞지 않습니다.\"\n","assert len(valid_image_list) == len(valid_annotations_list), \"valid 이미지 파일의 수와 annotation 파일의 수가 맞지 않습니다.\"\n","print(len(train_image_list), len(valid_image_list))"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["sample_image_path = train_image_list[400]\n","sample_annot_path = train_annotations_list[400]"]},{"cell_type":"markdown","metadata":{},"source":["# Utilities"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1629287086999,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"rWu_gp0o_ugb"},"outputs":[],"source":["#  annotation txt file로부터 ground truth logit 반환 \n","def get_gt_logit(txt_path):\n","  txt_path = Path(txt_path)\n","  with open(txt_path, 'r', encoding='utf-8') as txt:\n","    string = txt.readline()\n","    list_str = string.split()\n","    gt_logit = int(list_str[0])\n","\n","  return gt_logit\n","\n","# gt logit을 넣으면 gt name을 반환 \n","def logit2name(gt_logit):  # input : annotations txt file들의 list\n","  label_dict = {}\n","  with open('C:/Users/user/Drive/s-hero/Code/data.yaml', 'r') as f:\n","    data = yaml.load(f, Loader=yaml.FullLoader)\n","    class_list = data['names']\n","\n","    for idx in range(len(class_list)):\n","      name = class_list[idx]\n","      label_dict[idx] = name\n","\n","    gt_name = label_dict[gt_logit]\n","    return gt_name\n","\n","# annotation txt file path로부터 bbox 좌표 검출 \n","def get_bbox(annot_path):\n","  txt_path = Path(annot_path)\n","  with open(txt_path, 'r', encoding='UTF8') as txt:\n","    string = txt.readline()\n","    list_str = string.split()\n","    x, y, w, h = list_str[1:5]\n","    \n","  return x, y, w, h "]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["5\n"]}],"source":["print(get_gt_logit(sample_annot_path))"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1629287288793,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"TrBmz8IgfEVH","outputId":"c46ac2d1-ca0b-4826-bf25-0f0597ed5b94"},"outputs":[{"name":"stdout","output_type":"stream","text":["B_Misordered\n"]}],"source":["print(logit2name(get_gt_logit(sample_annot_path)))"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":401,"status":"ok","timestamp":1629287089753,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"1nb688I7e1pX","outputId":"803eb269-312f-4ea8-840a-72a02e39b67f"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.468750 0.493056 0.223438 0.791667\n"]}],"source":["x, y, w, h = get_bbox(sample_annot_path)\n","print(x, y, w, h)"]},{"cell_type":"markdown","metadata":{"id":"s1GEGVjXL5-z"},"source":["# Dataset & Augmentation"]},{"cell_type":"markdown","metadata":{},"source":["## using torchvision"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"svZCONEaL5-4"},"outputs":[],"source":["from torchvision import transforms\n","import numpy as np\n","from PIL import Image\n","import os\n","from pathlib import Path\n","\n","def Mytransform (size=224, use_resizecrop = True, use_flip = True, use_color_jitter = False, use_gray_scale = False, use_normalize = False):\n","    resize_crop = transforms.RandomResizedCrop(size=size)\n","    horizontal_flip = transforms.RandomHorizontalFlip(p=0.5)\n","    color_jitter = transforms.RandomApply([\n","        transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)\n","    ], p=0.8)\n","    gray_scale = transforms.RandomGrayscale(p=0.2)\n","    normalize = transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n","    to_tensor = transforms.ToTensor()\n","    \n","    transforms_array = np.array([resize_crop, horizontal_flip, color_jitter, gray_scale, to_tensor, normalize])\n","    transforms_mask = np.array([use_resizecrop, use_flip, use_color_jitter, use_gray_scale, True, use_normalize])\n","    transform = transforms.Compose(transforms_array[transforms_mask])\n","\n","    return transform"]},{"cell_type":"markdown","metadata":{},"source":["## using albumentations"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"mWQDLwoTBdSJ"},"outputs":[],"source":["import albumentations as A\n","import albumentations.pytorch as AP\n","import cv2\n","\n","AlbuTransform = A.Compose([\n","        A.Resize(416, 416),                   \n","        A.RandomResizedCrop(height=300,\n","                            width=300,\n","                            scale=(0.5, 1.0),\n","                            ratio=(0.75, 1.25), \n","                            interpolation=1, \n","                            always_apply=False, \n","                            p=0.5),\n","        A.HorizontalFlip(p=0.5),\n","        A.RandomBrightnessContrast(p=0.3),\n","        A.Affine(rotate=(-180, 180),\n","                shear=(-45, 45),\n","                p=0.5),\n","        A.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","        AP.ToTensorV2()\n","        ]\n","        ,bbox_params = A.BboxParams(format='yolo', min_area=1024, min_visibility=0.3))"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"0me5ovvPL5-2"},"outputs":[],"source":["# Dataset 정의\n","\n","import pandas as pd\n","import torch\n","from PIL import Image\n","from torch.utils.data import Dataset\n","from skimage import io\n","from pathlib import Path\n","\n","class Mydataset(Dataset):\n","  # root = '/content/\n","  def __init__(self, root, mode = 'train', transform = None):\n","    self.root = os.path.join(root, mode)\n","    self.images = sorted(glob(self.root + '/images/*.jpg'))\n","    self.annotations = sorted(glob(self.root + '/labels/*.txt'))\n","\n","  def __len__(self):\n","    assert len(self.images) == len(self.annotations), \"이미지 파일의 수와 annotation 파일의 수가 맞지 않습니다.\"\n","    return len(self.annotations) \n","\n","  def __getitem__(self, idx): # dataset중에 이미지 혹은 레이블을 하나씩 불러오는 함수 \n","    annotation = self.annotations[idx]\n","    label = self.get_gt_logit(annotation)\n","    if self.transform:\n","      image = self.transform(image)\n","    return image, label\n","      "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"HDVXqgdkL5-7"},"source":["# Training"]},{"cell_type":"markdown","metadata":{},"source":["## Hyperparameter evolve"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":830039,"status":"ok","timestamp":1629231307877,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"X9JOHTz1KToi","outputId":"5bf4e497-b816-4730-8f92-ca4bd8d0090b"},"outputs":[],"source":["# %cd C:\\Users\\user\\Drive\\s-hero\\code\\yolov5\n","# !python train.py --img 640 --batch 32 --epochs 100  --data C:/Users/user/Drive/s-hero/Code/data.yaml --weights yolov5m.pt --hyp hyp.finetune.yaml --name m_b32_500epoch_100evolve\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# from yolov5.utils.plots import plot_evolve\n","# plot_evolve(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\runs\\evolve\\medium_batch32_100epoch_100evolve\\evolve.csv')\n","# Image.open(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\runs\\evolve\\medium_batch32_100epoch_100evolve\\evolve.png')"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["#!python train.py --img 640 --batch 32 --epochs 500 --data C:/Users/user/Drive/s-hero/Code/data.yaml --weights yolov5m.pt --hyp C:/Users/user/Drive/s-hero/Code/yolov5/runs/evolve/medium_batch32_100epoch_100evolve/hyp_evolve.yaml --name m_b32_500epoch_100evo"]},{"cell_type":"markdown","metadata":{},"source":["# Inference"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6545,"status":"ok","timestamp":1629231314950,"user":{"displayName":"성균관대학교최준수","photoUrl":"","userId":"03698814127107115075"},"user_tz":-540},"id":"giHTHwzELhIS","outputId":"926d1897-c692-43bd-fe3d-bfe1d766c539"},"outputs":[],"source":["# %cd C:\\Users\\user\\Drive\\s-hero\\Code\n","# !python ./yolov5/detect.py --source ./sample.mp4 --weights C:/Users/user/Drive/s-hero/Code/yolov5/runs/train/m_b32_300epoch_evo/weights/best.pt --name m_conf_0.6 --img 640 --device 0 --conf 0.6"]},{"cell_type":"markdown","metadata":{},"source":["# Grad-CAM"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["c:\\Users\\user\\Drive\\s-hero\\Code\n","c:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\n"]}],"source":["# %cd c:\\Users\\user\\Drive\\s-hero\\Code\\pytorch-grad-cam \n","# from pytorch_grad_cam import GradCAM, GradCAMPlusPlus\n","# from pytorch_grad_cam.guided_backprop import GuidedBackpropReLUModel\n","# from pytorch_grad_cam.utils.image import preprocess_image, deprocess_image, show_cam_on_image\n","%cd c:\\Users\\user\\Drive\\s-hero\\Code\n","from grad_cam import GradCam, GuidedBackpropReLUModel, show_cams, show_gbs, preprocess_image\n","\n","%cd c:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\n","# from yolov5.utils.augmentations import *\n","# from yolov5.utils.datasets import *\n","\n","from yolov5 import train, detect\n","from yolov5.models.common import *\n","from yolov5.models.yolo import *\n","from yolov5.models.yolo import Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","# ckpt = {'epoch': epoch,\n","#         'best_fitness': best_fitness,\n","#         'model': deepcopy(de_parallel(model)).half(),\n","#         'ema': deepcopy(ema.ema).half(),\n","#         'updates': ema.updates,\n","#         'optimizer': optimizer.state_dict(),\n","#         'wandb_id': loggers.wandb.wandb_run.id if loggers.wandb else None}"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# from collections import OrderedDict\n","# from torchsummary import summary\n","\n","# new_dict = OrderedDict()\n","# empty_dict = OrderedDict()\n","\n","# for key, value in model.state_dict().items():\n","#     value = value.type(torch.FloatTensor)\n","#     new_dict.update({key : value})\n","\n","# model.load_state_dict(empty_dict, strict=False)\n","\n","# model.load_state_dict(new_dict)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["Model(\n","  (model): Sequential(\n","    (0): Conv(\n","      (conv): Conv2d(3, 48, kernel_size=(6, 6), stride=(2, 2), padding=(2, 2), bias=False)\n","      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (1): Conv(\n","      (conv): Conv2d(48, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (2): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(96, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(48, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (3): Conv(\n","      (conv): Conv2d(96, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (4): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (3): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (5): Conv(\n","      (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (6): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (2): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (3): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (4): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (5): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (7): Conv(\n","      (conv): Conv2d(384, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (8): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (9): SPPF(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n","    )\n","    (10): Conv(\n","      (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (11): Upsample(scale_factor=2.0, mode=nearest)\n","    (12): Concat()\n","    (13): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (14): Conv(\n","      (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (15): Upsample(scale_factor=2.0, mode=nearest)\n","    (16): Concat()\n","    (17): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(96, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (18): Conv(\n","      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (19): Concat()\n","    (20): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(192, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (21): Conv(\n","      (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","      (act): SiLU()\n","    )\n","    (22): Concat()\n","    (23): C3(\n","      (cv1): Conv(\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv2): Conv(\n","        (conv): Conv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (cv3): Conv(\n","        (conv): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","        (bn): BatchNorm2d(768, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","        (act): SiLU()\n","      )\n","      (m): Sequential(\n","        (0): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","        (1): Bottleneck(\n","          (cv1): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","          (cv2): Conv(\n","            (conv): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","            (bn): BatchNorm2d(384, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n","            (act): SiLU()\n","          )\n","        )\n","      )\n","    )\n","    (24): Detect(\n","      (m): ModuleList(\n","        (0): Conv2d(192, 39, kernel_size=(1, 1), stride=(1, 1))\n","        (1): Conv2d(384, 39, kernel_size=(1, 1), stride=(1, 1))\n","        (2): Conv2d(768, 39, kernel_size=(1, 1), stride=(1, 1))\n","      )\n","    )\n","  )\n",")"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["# with open(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\models\\yolov5s.yaml', 'r') as f:\n","#     v5s = yaml.load(f, Loader=yaml.FullLoader)\n","# model = Model(v5s, 3, 8, None)\n","# ckpt = torch.load(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\runs\\train\\small_b32_50epoch_100evo\\weights\\best.pt')\n","# weight = ckpt['model'].state_dict()\n","# model.load_state_dict(weight)\n","# model.eval()\n","\n","with open(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\models\\yolov5m.yaml', 'r') as f:\n","    v5m = yaml.load(f, Loader=yaml.FullLoader)   \n","model = Model(v5m, 3, 8, None)\n","ckpt = torch.load(r'C:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\runs\\train\\m_b32_300epoch_evo\\weights\\best.pt')\n","weight = ckpt['model'].state_dict()\n","model.load_state_dict(weight)\n","model.eval()"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["====================================================================================================\n","Layer (type:depth-idx)                             Output Shape              Param #\n","====================================================================================================\n","Model                                              --                        --\n","├─Sequential: 1                                    --                        --\n","│    └─Detect: 2                                   --                        --\n","│    │    └─ModuleList: 3-1                        --                        52,533\n","│    └─Conv: 2-1                                   [32, 48, 990, 510]        --\n","│    │    └─Conv2d: 3-2                            [32, 48, 990, 510]        5,184\n","│    │    └─BatchNorm2d: 3-3                       [32, 48, 990, 510]        96\n","│    │    └─SiLU: 3-4                              [32, 48, 990, 510]        --\n","│    └─Conv: 2-2                                   [32, 96, 495, 255]        --\n","│    │    └─Conv2d: 3-5                            [32, 96, 495, 255]        41,472\n","│    │    └─BatchNorm2d: 3-6                       [32, 96, 495, 255]        192\n","│    │    └─SiLU: 3-7                              [32, 96, 495, 255]        --\n","│    └─C3: 2-3                                     [32, 96, 495, 255]        --\n","│    │    └─Conv: 3-8                              [32, 48, 495, 255]        4,704\n","│    │    └─Sequential: 3-9                        [32, 48, 495, 255]        46,464\n","│    │    └─Conv: 3-10                             [32, 48, 495, 255]        4,704\n","│    │    └─Conv: 3-11                             [32, 96, 495, 255]        9,408\n","│    └─Conv: 2-4                                   [32, 192, 248, 128]       --\n","│    │    └─Conv2d: 3-12                           [32, 192, 248, 128]       165,888\n","│    │    └─BatchNorm2d: 3-13                      [32, 192, 248, 128]       384\n","│    │    └─SiLU: 3-14                             [32, 192, 248, 128]       --\n","│    └─C3: 2-5                                     [32, 192, 248, 128]       --\n","│    │    └─Conv: 3-15                             [32, 96, 248, 128]        18,624\n","│    │    └─Sequential: 3-16                       [32, 96, 248, 128]        370,176\n","│    │    └─Conv: 3-17                             [32, 96, 248, 128]        18,624\n","│    │    └─Conv: 3-18                             [32, 192, 248, 128]       37,248\n","│    └─Conv: 2-6                                   [32, 384, 124, 64]        --\n","│    │    └─Conv2d: 3-19                           [32, 384, 124, 64]        663,552\n","│    │    └─BatchNorm2d: 3-20                      [32, 384, 124, 64]        768\n","│    │    └─SiLU: 3-21                             [32, 384, 124, 64]        --\n","│    └─C3: 2-7                                     [32, 384, 124, 64]        --\n","│    │    └─Conv: 3-22                             [32, 192, 124, 64]        74,112\n","│    │    └─Sequential: 3-23                       [32, 192, 124, 64]        2,216,448\n","│    │    └─Conv: 3-24                             [32, 192, 124, 64]        74,112\n","│    │    └─Conv: 3-25                             [32, 384, 124, 64]        148,224\n","│    └─Conv: 2-8                                   [32, 768, 62, 32]         --\n","│    │    └─Conv2d: 3-26                           [32, 768, 62, 32]         2,654,208\n","│    │    └─BatchNorm2d: 3-27                      [32, 768, 62, 32]         1,536\n","│    │    └─SiLU: 3-28                             [32, 768, 62, 32]         --\n","│    └─C3: 2-9                                     [32, 768, 62, 32]         --\n","│    │    └─Conv: 3-29                             [32, 384, 62, 32]         295,680\n","│    │    └─Sequential: 3-30                       [32, 384, 62, 32]         2,952,192\n","│    │    └─Conv: 3-31                             [32, 384, 62, 32]         295,680\n","│    │    └─Conv: 3-32                             [32, 768, 62, 32]         591,360\n","│    └─SPPF: 2-10                                  [32, 768, 62, 32]         --\n","│    │    └─Conv: 3-33                             [32, 384, 62, 32]         295,680\n","│    │    └─MaxPool2d: 3-34                        [32, 384, 62, 32]         --\n","│    │    └─MaxPool2d: 3-35                        [32, 384, 62, 32]         --\n","│    │    └─MaxPool2d: 3-36                        [32, 384, 62, 32]         --\n","│    │    └─Conv: 3-37                             [32, 768, 62, 32]         1,181,184\n","│    └─Conv: 2-11                                  [32, 384, 62, 32]         --\n","│    │    └─Conv2d: 3-38                           [32, 384, 62, 32]         294,912\n","│    │    └─BatchNorm2d: 3-39                      [32, 384, 62, 32]         768\n","│    │    └─SiLU: 3-40                             [32, 384, 62, 32]         --\n","│    └─Upsample: 2-12                              [32, 384, 124, 64]        --\n","│    └─Concat: 2-13                                [32, 768, 124, 64]        --\n","│    └─C3: 2-14                                    [32, 384, 124, 64]        --\n","│    │    └─Conv: 3-41                             [32, 192, 124, 64]        147,840\n","│    │    └─Sequential: 3-42                       [32, 192, 124, 64]        738,816\n","│    │    └─Conv: 3-43                             [32, 192, 124, 64]        147,840\n","│    │    └─Conv: 3-44                             [32, 384, 124, 64]        148,224\n","│    └─Conv: 2-15                                  [32, 192, 124, 64]        --\n","│    │    └─Conv2d: 3-45                           [32, 192, 124, 64]        73,728\n","│    │    └─BatchNorm2d: 3-46                      [32, 192, 124, 64]        384\n","│    │    └─SiLU: 3-47                             [32, 192, 124, 64]        --\n","│    └─Upsample: 2-16                              [32, 192, 248, 128]       --\n","│    └─Concat: 2-17                                [32, 384, 248, 128]       --\n","│    └─C3: 2-18                                    [32, 192, 248, 128]       --\n","│    │    └─Conv: 3-48                             [32, 96, 248, 128]        37,056\n","│    │    └─Sequential: 3-49                       [32, 96, 248, 128]        185,088\n","│    │    └─Conv: 3-50                             [32, 96, 248, 128]        37,056\n","│    │    └─Conv: 3-51                             [32, 192, 248, 128]       37,248\n","│    └─Conv: 2-19                                  [32, 192, 124, 64]        --\n","│    │    └─Conv2d: 3-52                           [32, 192, 124, 64]        331,776\n","│    │    └─BatchNorm2d: 3-53                      [32, 192, 124, 64]        384\n","│    │    └─SiLU: 3-54                             [32, 192, 124, 64]        --\n","│    └─Concat: 2-20                                [32, 384, 124, 64]        --\n","│    └─C3: 2-21                                    [32, 384, 124, 64]        --\n","│    │    └─Conv: 3-55                             [32, 192, 124, 64]        74,112\n","│    │    └─Sequential: 3-56                       [32, 192, 124, 64]        738,816\n","│    │    └─Conv: 3-57                             [32, 192, 124, 64]        74,112\n","│    │    └─Conv: 3-58                             [32, 384, 124, 64]        148,224\n","│    └─Conv: 2-22                                  [32, 384, 62, 32]         --\n","│    │    └─Conv2d: 3-59                           [32, 384, 62, 32]         1,327,104\n","│    │    └─BatchNorm2d: 3-60                      [32, 384, 62, 32]         768\n","│    │    └─SiLU: 3-61                             [32, 384, 62, 32]         --\n","│    └─Concat: 2-23                                [32, 768, 62, 32]         --\n","│    └─C3: 2-24                                    [32, 768, 62, 32]         --\n","│    │    └─Conv: 3-62                             [32, 384, 62, 32]         295,680\n","│    │    └─Sequential: 3-63                       [32, 384, 62, 32]         2,952,192\n","│    │    └─Conv: 3-64                             [32, 384, 62, 32]         295,680\n","│    │    └─Conv: 3-65                             [32, 768, 62, 32]         591,360\n","│    └─Detect: 2-25                                [32, 124992, 13]          --\n","====================================================================================================\n","Total params: 20,899,605\n","Trainable params: 20,899,605\n","Non-trainable params: 0\n","Total mult-adds (T): 3.80\n","====================================================================================================\n","Input size (MB): 775.53\n","Forward/backward pass size (MB): 115228.31\n","Params size (MB): 83.60\n","Estimated Total Size (MB): 116087.44\n","===================================================================================================="]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# from torchsummary import summary\n","from torchinfo import summary\n","\n","summary(model, (32, 3, 1980, 1020))"]},{"cell_type":"code","execution_count":51,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 3, 1080, 1920])"]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["idx1 = np.random.randint(low=0, high=len(valid_annotations_list))\n","idx2 = np.random.randint(low=0, high=len(valid_annotations_list))\n","img1 = torch.as_tensor(np.asarray(Image.open(valid_image_list[idx1]))).permute(2,0,1)\n","img2 = torch.as_tensor(np.asarray(Image.open(valid_image_list[idx2]))).permute(2,0,1)\n","\n","img1, img2 = img1.view(1,img1.size(0),img1.size(1),img1.size(2))/255, img2.view(1,img2.size(0),img2.size(1),img2.size(2))/255\n","img = torch.cat((img1, img2))\n","img.shape"]},{"cell_type":"code","execution_count":53,"metadata":{},"outputs":[{"ename":"RuntimeError","evalue":"torch.cat(): Sizes of tensors must match except in dimension 1. Got 136 and 135 in dimension 2 (The offending index is 1)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14540/3427906382.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mc:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\models\\yolo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, augment, profile, visualize)\u001b[0m\n\u001b[0;32m    124\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_augment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# augmented inference, None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 126\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# single-scale inference, train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_forward_augment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\models\\yolo.py\u001b[0m in \u001b[0;36m_forward_once\u001b[1;34m(self, x, profile, visualize)\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_profile_one_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# save output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1051\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\user\\Drive\\s-hero\\Code\\yolov5\\models\\common.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    272\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: torch.cat(): Sizes of tensors must match except in dimension 1. Got 136 and 135 in dimension 2 (The offending index is 1)"]}],"source":["model.forward(img)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 3, 224, 224])\n","2\n"]}],"source":["#python cam.py --image-path C:/Users/user/Drive/s-hero/Code/Data/valid/images/A1_044.jpg --method gradcam \n","model.to('cpu')\n","grad_cam = GradCam(model=model, blob_name='model', target_layer_names = [i for i in range(24)], use_cuda=False)\n","\n","idx = np.random.randint(low=0, high=len(valid_annotations_list))\n","img = cv2.imread(valid_image_list[idx], 1)\n","img = np.float32(cv2.resize(img, (224, 224))) / 255  # C, H, W\n","\n","inputs = preprocess_image(img)\n","print(inputs.shape)\n","annot = valid_annotations_list[idx]\n","target_category = get_gt_logit(annot)\n","print(target_category)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cam = grad_cam(inputs=inputs, index=target_category)\n","\n","show_cams(img, cam)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from efficientnet_pytorch import EfficientNet\n","from torchvision.models import resnet50\n","effnet = EfficientNet.from_pretrained(\"efficientnet-b4\", advprop=True)\n","resnet = resnet50(pretrained=True)\n","\n","model = effnet\n","model.eval()\n","grad_cam = GradCam(model=model, blob_name='_blocks', target_layer_names = [str(i) for i in range(16)], use_cuda=False)\n","\n","idx = np.random.randint(low=0, high=len(valid_annotations_list))\n","img = cv2.imread(valid_image_list[idx], 1)\n","img = np.float32(cv2.resize(img, (224, 224))) / 255  # C, H, W\n","\n","inputs = preprocess_image(img)\n","print(inputs.shape)\n","annot = valid_annotations_list[idx]\n","target_category = get_gt_logit(annot)\n","\n","cam = grad_cam(inputs, target_category)\n","show_cams(img, cam)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["cd-"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"baseline.ipynb","provenance":[]},"interpreter":{"hash":"790dd84243cf46e5e9b666dfb25c5c04395df9f262adebb0a07d3d946c1bc019"},"kernelspec":{"display_name":"Python 3.9.7 64-bit ('torch': conda)","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":2}
